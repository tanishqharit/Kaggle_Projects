{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tanishqharit21/twitter-sentiment-nlp-lr?scriptVersionId=219702735\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"GFG Project - Project YT Link :\n\nhttps://www.youtube.com/watch?v=4YGkfAd2iXM&list=PLqM7alHXFySGTcwBQV-hYDkYAPJ4EPHe9\n\nKaggle Dataset Link : \n\nhttps://www.kaggle.com/datasets/kazanova/sentiment140","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re                                                    # Regular Expression \nfrom nltk.corpus import stopwords                            # Natural Language Procesing\nfrom nltk.stem.porter import PorterStemmer                   # To stem words \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split         # To split data into train and test set \nfrom sklearn.linear_model import LogisticRegression          # Logistic Regression \nfrom sklearn.metrics import accuracy_score                   # To calculate accuracy and performance ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:04:29.684885Z","iopub.execute_input":"2025-01-28T23:04:29.685151Z","iopub.status.idle":"2025-01-28T23:04:32.940494Z","shell.execute_reply.started":"2025-01-28T23:04:29.685124Z","shell.execute_reply":"2025-01-28T23:04:32.939602Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:04:37.51593Z","iopub.execute_input":"2025-01-28T23:04:37.516328Z","iopub.status.idle":"2025-01-28T23:04:37.78168Z","shell.execute_reply.started":"2025-01-28T23:04:37.516268Z","shell.execute_reply":"2025-01-28T23:04:37.780755Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Printing stopwords in English\nprint(stopwords.words('english'))\n# These words are not required for our model, they have not much contextual importance\n# We need to reduce size and complexity of our data (1.6 million tweets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:04:41.597573Z","iopub.execute_input":"2025-01-28T23:04:41.597911Z","iopub.status.idle":"2025-01-28T23:04:41.60551Z","shell.execute_reply.started":"2025-01-28T23:04:41.597885Z","shell.execute_reply":"2025-01-28T23:04:41.604557Z"}},"outputs":[{"name":"stdout","text":"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Loading data as pandas df\ntwitter_data = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv',\n                              encoding = 'ISO-8859-1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:04:44.752687Z","iopub.execute_input":"2025-01-28T23:04:44.753101Z","iopub.status.idle":"2025-01-28T23:04:51.599856Z","shell.execute_reply.started":"2025-01-28T23:04:44.753069Z","shell.execute_reply":"2025-01-28T23:04:51.598843Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Rows and columns\ntwitter_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:04:55.942733Z","iopub.execute_input":"2025-01-28T23:04:55.943099Z","iopub.status.idle":"2025-01-28T23:04:55.948891Z","shell.execute_reply.started":"2025-01-28T23:04:55.943069Z","shell.execute_reply":"2025-01-28T23:04:55.947951Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(1599999, 6)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Peeking data\ntwitter_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:04:58.261357Z","iopub.execute_input":"2025-01-28T23:04:58.261699Z","iopub.status.idle":"2025-01-28T23:04:58.285106Z","shell.execute_reply.started":"2025-01-28T23:04:58.261673Z","shell.execute_reply":"2025-01-28T23:04:58.284056Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n\n  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n0  is upset that he can't update his Facebook by ...                                                                   \n1  @Kenichan I dived many times for the ball. Man...                                                                   \n2    my whole body feels itchy and like its on fire                                                                    \n3  @nationwideclass no, it's not behaving at all....                                                                   \n4                      @Kwesidei not the whole crew                                                                    ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1467810369</th>\n      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n      <th>NO_QUERY</th>\n      <th>_TheSpecialOne_</th>\n      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811372</td>\n      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"There is a problem with this data. It has no column names.\n\nIn the above data peek, the column names bar is also data.\n\nSo, we need to name the columns manually. We will use the same name as present in Kaggle dataset overview.","metadata":{}},{"cell_type":"code","source":"# Naming the columns\ncolumn_names = ['target', 'id', 'date', 'flag', 'user', 'text']\n# Reading the dataset again\ntwitter_data = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv',\n                              names = column_names, encoding = 'ISO-8859-1')\n# Peeking again dataframe again\ntwitter_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:05:01.84761Z","iopub.execute_input":"2025-01-28T23:05:01.847977Z","iopub.status.idle":"2025-01-28T23:05:06.347222Z","shell.execute_reply.started":"2025-01-28T23:05:01.847947Z","shell.execute_reply":"2025-01-28T23:05:06.346253Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   target          id                          date      flag  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1    scotthamilton  is upset that he can't update his Facebook by ...  \n2         mattycus  @Kenichan I dived many times for the ball. Man...  \n3          ElleCTF    my whole body feels itchy and like its on fire   \n4           Karoli  @nationwideclass no, it's not behaving at all....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Now, according to dataset overview, the 'target' column contains either 0 or 4.\n\nHere, 0 = negative, 4 = positive (Sentiment)","metadata":{}},{"cell_type":"code","source":"# Checking any missing values\ntwitter_data.isnull().sum()    # Total missing values in all columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:05:09.815569Z","iopub.execute_input":"2025-01-28T23:05:09.816022Z","iopub.status.idle":"2025-01-28T23:05:10.167851Z","shell.execute_reply.started":"2025-01-28T23:05:09.815985Z","shell.execute_reply":"2025-01-28T23:05:10.166824Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"target    0\nid        0\ndate      0\nflag      0\nuser      0\ntext      0\ndtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Good, there are no missing values in the dataset.","metadata":{}},{"cell_type":"code","source":"# Checking the distribution of the 'target' column\ntwitter_data['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:05:13.193692Z","iopub.execute_input":"2025-01-28T23:05:13.194058Z","iopub.status.idle":"2025-01-28T23:05:13.216656Z","shell.execute_reply.started":"2025-01-28T23:05:13.194026Z","shell.execute_reply":"2025-01-28T23:05:13.215704Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"target\n0    800000\n4    800000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"So, 8 Lakh tweets have positive sentiment (target = 4) and\n\nagain 8 Lakh tweets have negative sentiment (target = 0).\n\nGood, this data is evenly distributed.","metadata":{}},{"cell_type":"markdown","source":"#### Stemming\n- It is a process of reducing a word to its root word.\n- Example : actor, actress, acting = act\n- We are doing this to reduce dataset.\n- For this we will use PorterStemmer which we have imported.","metadata":{}},{"cell_type":"code","source":"# Intialising Porter Stemmer\nport_stem = PorterStemmer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:05:16.460119Z","iopub.execute_input":"2025-01-28T23:05:16.460507Z","iopub.status.idle":"2025-01-28T23:05:16.464659Z","shell.execute_reply.started":"2025-01-28T23:05:16.46048Z","shell.execute_reply":"2025-01-28T23:05:16.463585Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Improving 'text' column - Building a template for stemming  \n\ndef stemming(content):  # Here, content is each tweet present in dataset \n\n    stemmed_content = re.sub('[^a-zA-Z]',' ', content)  # Only alphabets, no [1,2,@,#,$...]\n    stemmed_content = stemmed_content.lower()           # Converting words to lower case\n    stemmed_content = stemmed_content.split()           # splitting words and storing in a list \n    \n    stemmed_content = [port_stem.stem(word) for word in stemmed_content\n                          if not word in stopwords.words('english')]\n    # Performing stem function only word which are not in stopwords.\n    # We dont want stop words.\n\n    stemmed_content = ' '.join(stemmed_content)\n    return stemmed_content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:05:33.186279Z","iopub.execute_input":"2025-01-28T23:05:33.186668Z","iopub.status.idle":"2025-01-28T23:05:33.192951Z","shell.execute_reply.started":"2025-01-28T23:05:33.186639Z","shell.execute_reply":"2025-01-28T23:05:33.191869Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Creating a new column in dataframe called 'stemmed_content'\n# and applying 'stemming' function to the 'text' column.\ntwitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)\n\n# CAUTION : This will take alot of time, 1.6 million rows.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:05:47.372249Z","iopub.execute_input":"2025-01-28T23:05:47.372723Z","iopub.status.idle":"2025-01-28T23:51:30.820654Z","shell.execute_reply.started":"2025-01-28T23:05:47.372685Z","shell.execute_reply":"2025-01-28T23:51:30.81973Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Now, lets check our column \ntwitter_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:56:40.462534Z","iopub.execute_input":"2025-01-28T23:56:40.462913Z","iopub.status.idle":"2025-01-28T23:56:40.475058Z","shell.execute_reply.started":"2025-01-28T23:56:40.462881Z","shell.execute_reply":"2025-01-28T23:56:40.47404Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   target          id                          date      flag  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n\n              user                                               text  \\\n0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n1    scotthamilton  is upset that he can't update his Facebook by ...   \n2         mattycus  @Kenichan I dived many times for the ball. Man...   \n3          ElleCTF    my whole body feels itchy and like its on fire    \n4           Karoli  @nationwideclass no, it's not behaving at all....   \n\n                                     stemmed_content  \n0  switchfoot http twitpic com zl awww bummer sho...  \n1  upset updat facebook text might cri result sch...  \n2  kenichan dive mani time ball manag save rest g...  \n3                    whole bodi feel itchi like fire  \n4                      nationwideclass behav mad see  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n      <th>stemmed_content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n      <td>switchfoot http twitpic com zl awww bummer sho...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>upset updat facebook text might cri result sch...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>kenichan dive mani time ball manag save rest g...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>whole bodi feel itchi like fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>nationwideclass behav mad see</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"Now, to build our sentiment analysis model, we will use 'target' and 'stemmed_content'.\n\nWe dont need 'id', 'date', 'flag', 'user', 'text' columns data.","metadata":{}},{"cell_type":"code","source":"# Seprating data and label \nX = twitter_data['stemmed_content'].values \nY = twitter_data['target'].values ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:56:52.651996Z","iopub.execute_input":"2025-01-28T23:56:52.652371Z","iopub.status.idle":"2025-01-28T23:56:52.656658Z","shell.execute_reply.started":"2025-01-28T23:56:52.652337Z","shell.execute_reply":"2025-01-28T23:56:52.655706Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Data \nprint(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:56:56.938956Z","iopub.execute_input":"2025-01-28T23:56:56.939317Z","iopub.status.idle":"2025-01-28T23:56:56.944191Z","shell.execute_reply.started":"2025-01-28T23:56:56.939265Z","shell.execute_reply":"2025-01-28T23:56:56.94324Z"}},"outputs":[{"name":"stdout","text":"['switchfoot http twitpic com zl awww bummer shoulda got david carr third day'\n 'upset updat facebook text might cri result school today also blah'\n 'kenichan dive mani time ball manag save rest go bound' ...\n 'readi mojo makeov ask detail'\n 'happi th birthday boo alll time tupac amaru shakur'\n 'happi charitytuesday thenspcc sparkschar speakinguph h']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Label\nprint(Y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:01.244909Z","iopub.execute_input":"2025-01-28T23:57:01.245234Z","iopub.status.idle":"2025-01-28T23:57:01.250323Z","shell.execute_reply.started":"2025-01-28T23:57:01.245208Z","shell.execute_reply":"2025-01-28T23:57:01.249274Z"}},"outputs":[{"name":"stdout","text":"[0 0 0 ... 4 4 4]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Splitting data into training and test data using Train_Test_Split function \n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, \n                                                      stratify = Y, random_state = 2)\n\n# test_size = 0.2 MEANS 20% of data will go to test data and 80% will go to test data. \n# stratify = Y MEANS there should be equal number of positive (4) and negative (1) in both data.\n# random_state = 2 (to avoid splitting data randomly)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:06.313876Z","iopub.execute_input":"2025-01-28T23:57:06.3142Z","iopub.status.idle":"2025-01-28T23:57:07.038014Z","shell.execute_reply.started":"2025-01-28T23:57:06.314174Z","shell.execute_reply":"2025-01-28T23:57:07.037092Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Training data (stemmed content)\nprint(f'Original data: {X.shape}')\nprint(f'Training data: {X_train.shape}')\nprint(f'Testing data: {X_test.shape}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:11.963071Z","iopub.execute_input":"2025-01-28T23:57:11.963424Z","iopub.status.idle":"2025-01-28T23:57:11.969452Z","shell.execute_reply.started":"2025-01-28T23:57:11.963397Z","shell.execute_reply":"2025-01-28T23:57:11.968559Z"}},"outputs":[{"name":"stdout","text":"Original data: (1600000,)\nTraining data: (1280000,)\nTesting data: (320000,)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Machine Learning does not understand text, so we need to convert textual data to numerical data using Vectorizer.","metadata":{}},{"cell_type":"code","source":"# Converting textual data to numerical data\nvectorizer = TfidfVectorizer()\n\nX_train = vectorizer.fit_transform(X_train)\nX_test = vectorizer.transform(X_test)\n\n# It will assign some importance to each individual word.\n# Vectorizer will give score to all the individual words.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:17.603778Z","iopub.execute_input":"2025-01-28T23:57:17.604092Z","iopub.status.idle":"2025-01-28T23:57:34.922804Z","shell.execute_reply.started":"2025-01-28T23:57:17.604068Z","shell.execute_reply":"2025-01-28T23:57:34.921866Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Let's check the converted numerical data\nprint(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:41.897451Z","iopub.execute_input":"2025-01-28T23:57:41.897778Z","iopub.status.idle":"2025-01-28T23:57:42.011353Z","shell.execute_reply.started":"2025-01-28T23:57:41.897752Z","shell.execute_reply":"2025-01-28T23:57:42.010315Z"}},"outputs":[{"name":"stdout","text":"  (0, 443066)\t0.4484755317023172\n  (0, 235045)\t0.41996827700291095\n  (0, 109306)\t0.3753708587402299\n  (0, 185193)\t0.5277679060576009\n  (0, 354543)\t0.3588091611460021\n  (0, 436713)\t0.27259876264838384\n  (1, 160636)\t1.0\n  (2, 288470)\t0.16786949597862733\n  (2, 132311)\t0.2028971570399794\n  (2, 150715)\t0.18803850583207948\n  (2, 178061)\t0.1619010109445149\n  (2, 409143)\t0.15169282335109835\n  (2, 266729)\t0.24123230668976975\n  (2, 443430)\t0.3348599670252845\n  (2, 77929)\t0.31284080750346344\n  (2, 433560)\t0.3296595898028565\n  (2, 406399)\t0.32105459490875526\n  (2, 129411)\t0.29074192727957143\n  (2, 407301)\t0.18709338684973031\n  (2, 124484)\t0.1892155960801415\n  (2, 109306)\t0.4591176413728317\n  (3, 172421)\t0.37464146922154384\n  (3, 411528)\t0.27089772444087873\n  (3, 388626)\t0.3940776331458846\n  (3, 56476)\t0.5200465453608686\n  :\t:\n  (1279996, 390130)\t0.22064742191076112\n  (1279996, 434014)\t0.2718945052332447\n  (1279996, 318303)\t0.21254698865277746\n  (1279996, 237899)\t0.2236567560099234\n  (1279996, 291078)\t0.17981734369155505\n  (1279996, 412553)\t0.18967045002348676\n  (1279997, 112591)\t0.7574829183045267\n  (1279997, 273084)\t0.4353549002982409\n  (1279997, 5685)\t0.48650358607431304\n  (1279998, 385313)\t0.4103285865588191\n  (1279998, 275288)\t0.38703346602729577\n  (1279998, 162047)\t0.34691726958159064\n  (1279998, 156297)\t0.3137096161546449\n  (1279998, 153281)\t0.28378968751027456\n  (1279998, 435463)\t0.2851807874350361\n  (1279998, 124765)\t0.32241752985927996\n  (1279998, 169461)\t0.2659980990397061\n  (1279998, 93795)\t0.21717768937055476\n  (1279998, 412553)\t0.2816582375021589\n  (1279999, 96224)\t0.5416162421321443\n  (1279999, 135384)\t0.6130934129868719\n  (1279999, 433612)\t0.3607341026233411\n  (1279999, 435572)\t0.31691096877786484\n  (1279999, 31410)\t0.248792678366695\n  (1279999, 242268)\t0.19572649660865402\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:46.664837Z","iopub.execute_input":"2025-01-28T23:57:46.66516Z","iopub.status.idle":"2025-01-28T23:57:46.690019Z","shell.execute_reply.started":"2025-01-28T23:57:46.665135Z","shell.execute_reply":"2025-01-28T23:57:46.689126Z"}},"outputs":[{"name":"stdout","text":"  (0, 420984)\t0.17915624523539803\n  (0, 409143)\t0.31430470598079707\n  (0, 398906)\t0.3491043873264267\n  (0, 388348)\t0.21985076072061738\n  (0, 279082)\t0.1782518010910344\n  (0, 271016)\t0.4535662391658828\n  (0, 171378)\t0.2805816206356073\n  (0, 138164)\t0.23688292264071403\n  (0, 132364)\t0.25525488955578596\n  (0, 106069)\t0.3655545001090455\n  (0, 67828)\t0.26800375270827315\n  (0, 31168)\t0.16247724180521766\n  (0, 15110)\t0.1719352837797837\n  (1, 366203)\t0.24595562404108307\n  (1, 348135)\t0.4739279595416274\n  (1, 256777)\t0.28751585696559306\n  (1, 217562)\t0.40288153995289894\n  (1, 145393)\t0.575262969264869\n  (1, 15110)\t0.211037449588008\n  (1, 6463)\t0.30733520460524466\n  (2, 400621)\t0.4317732461913093\n  (2, 256834)\t0.2564939661498776\n  (2, 183312)\t0.5892069252021465\n  (2, 89448)\t0.36340369428387626\n  (2, 34401)\t0.37916255084357414\n  :\t:\n  (319994, 123278)\t0.4530341382559843\n  (319995, 444934)\t0.3211092817599261\n  (319995, 420984)\t0.22631428606830145\n  (319995, 416257)\t0.23816465111736276\n  (319995, 324496)\t0.3613167933647574\n  (319995, 315813)\t0.28482299145634127\n  (319995, 296662)\t0.39924856793840147\n  (319995, 232891)\t0.25741278545890767\n  (319995, 213324)\t0.2683969144317078\n  (319995, 155493)\t0.2770682832971668\n  (319995, 109379)\t0.30208964848908326\n  (319995, 107868)\t0.3339934973754696\n  (319996, 438709)\t0.4143006291901984\n  (319996, 397506)\t0.9101400928717545\n  (319997, 444770)\t0.2668297951055569\n  (319997, 416695)\t0.29458327588067873\n  (319997, 349904)\t0.32484594100566083\n  (319997, 288421)\t0.48498483387153407\n  (319997, 261286)\t0.37323893626855326\n  (319997, 169411)\t0.403381646999604\n  (319997, 98792)\t0.4463892055808332\n  (319998, 438748)\t0.719789181620468\n  (319998, 130192)\t0.6941927210956169\n  (319999, 400636)\t0.2874420848216212\n  (319999, 389755)\t0.9577980203954275\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"TRAINING the machine learning model. In this case Logistic Regression (Classification Model).\n\nHere, 2 classes are positive tweet and negative tweet.","metadata":{}},{"cell_type":"code","source":"# ML Model\nmodel = LogisticRegression(max_iter = 1000)   # maximum_iterations = 1000 to perfect the accuracy.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:50.565826Z","iopub.execute_input":"2025-01-28T23:57:50.566157Z","iopub.status.idle":"2025-01-28T23:57:50.57021Z","shell.execute_reply.started":"2025-01-28T23:57:50.566132Z","shell.execute_reply":"2025-01-28T23:57:50.569326Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"Fitting the training data into the LogisticRegression model.","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, Y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T23:57:56.083012Z","iopub.execute_input":"2025-01-28T23:57:56.08335Z","iopub.status.idle":"2025-01-28T23:59:05.766761Z","shell.execute_reply.started":"2025-01-28T23:57:56.083323Z","shell.execute_reply":"2025-01-28T23:59:05.765816Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=1000)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Model Evaluation - Accuracy Score on the training data.\n\nX_train_prediction = model.predict(X_train)\ntraining_data_accuracy = accuracy_score(Y_train, X_train_prediction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T00:00:13.111157Z","iopub.execute_input":"2025-01-29T00:00:13.111562Z","iopub.status.idle":"2025-01-29T00:00:13.319344Z","shell.execute_reply.started":"2025-01-29T00:00:13.111529Z","shell.execute_reply":"2025-01-29T00:00:13.318252Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"print(f'Accuracy score on the training data {training_data_accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T00:00:16.849501Z","iopub.execute_input":"2025-01-29T00:00:16.849851Z","iopub.status.idle":"2025-01-29T00:00:16.854784Z","shell.execute_reply.started":"2025-01-29T00:00:16.849822Z","shell.execute_reply":"2025-01-29T00:00:16.853824Z"}},"outputs":[{"name":"stdout","text":"Accuracy score on the training data 0.81020703125\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"- Accuracy score of the model is 81%.\n- 81 out of 100 tweets, model can predict whether that tweet is positive or negative.\n\n#### But, But, But \n- We have not yet show the testing data to the model.\n- This accuracy score is on the training data only.\n- Lets show it some NEW tweets.","metadata":{}},{"cell_type":"code","source":"# Accuracy Score on the testing data.\n\nX_test_prediction = model.predict(X_test)\ntesting_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n\nprint(f'Accuracy score on the testing data {testing_data_accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T00:00:22.725136Z","iopub.execute_input":"2025-01-29T00:00:22.725508Z","iopub.status.idle":"2025-01-29T00:00:22.777942Z","shell.execute_reply.started":"2025-01-29T00:00:22.725477Z","shell.execute_reply":"2025-01-29T00:00:22.776925Z"}},"outputs":[{"name":"stdout","text":"Accuracy score on the testing data 0.7780125\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"- Training data accuracy and testing data accuracy are very close to each other.\n- Model has performed well.\n- If accuracy score of testing data (id very less) < accuracy score of training data :\n- Then this is called Overfitting (Model has learned nothing).\n\n### MODEL ACCURACY = 77.7%","metadata":{}},{"cell_type":"code","source":"# Saving the trained model\nimport pickle\nfilename = 'TSA_trained_model.sav'\npickle.dump(model, open(filename,'wb'))   # wb - is nothing but writing a new file (in binary format)\n\n# We are saving all the parameters and learning of the model in the file 'TSA_trained_model.sav'.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T00:00:27.579475Z","iopub.execute_input":"2025-01-29T00:00:27.57986Z","iopub.status.idle":"2025-01-29T00:00:27.588331Z","shell.execute_reply.started":"2025-01-29T00:00:27.579828Z","shell.execute_reply":"2025-01-29T00:00:27.587331Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"### Using Model for NEW Predictions","metadata":{}},{"cell_type":"code","source":"# Loading the saved model\n\nloaded_model = pickle.load(open(filename, 'rb'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T00:00:33.012574Z","iopub.execute_input":"2025-01-29T00:00:33.012969Z","iopub.status.idle":"2025-01-29T00:00:33.018469Z","shell.execute_reply.started":"2025-01-29T00:00:33.012938Z","shell.execute_reply":"2025-01-29T00:00:33.017567Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# 200th Tweet in the dataframe \n\nX_new = X_test[200]\nprint(f'True Label: {Y_test[200]}')\n\nprediction = loaded_model.predict(X_new)\n\nif (prediction[0] == 0):\n    print('Negative Tweet')\nelse:\n    print('Positive Tweet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T00:00:38.404745Z","iopub.execute_input":"2025-01-29T00:00:38.405131Z","iopub.status.idle":"2025-01-29T00:00:38.412762Z","shell.execute_reply.started":"2025-01-29T00:00:38.405097Z","shell.execute_reply":"2025-01-29T00:00:38.411657Z"}},"outputs":[{"name":"stdout","text":"True Label: 4\nPositive Tweet\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# There are so many tweets, lets take a random\n# 48294th tweet\n\nX_new = X_test[48294]\nprint(f'True Label: {Y_test[48294]}')\n\nprediction = loaded_model.predict(X_new)\n\nif (prediction[0] == 0):\n    print('Negative Tweet')\nelse:\n    print('Positive Tweet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T00:00:42.160829Z","iopub.execute_input":"2025-01-29T00:00:42.161162Z","iopub.status.idle":"2025-01-29T00:00:42.167832Z","shell.execute_reply.started":"2025-01-29T00:00:42.161135Z","shell.execute_reply":"2025-01-29T00:00:42.166878Z"}},"outputs":[{"name":"stdout","text":"True Label: 4\nPositive Tweet\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"So, our model is predicting tweets precisely.\n\nSometime, it may not predict precisely though.","metadata":{}}]}
